#! /bin/zsh

# Download a website spider-style with wget

if ! command -v zsh >/dev/null 2>&1; then
	echo 'wget is missing!'
	return 2
fi

if [[ $# != 1 ]]; then
	echo 'You must supply a URL to spider..'
	return 1
fi

# parse the domain from the incoming URL
PYTHON_CODE="from urllib.parse import urlparse; print(urlparse('$1').netloc)"
DOMAIN=$(python3 -c "$PYTHON_CODE")

wget --recursive \
     --no-clobber \
     --page-requisites \
     --html-extension \
     --convert-links \
     --restrict-file-names=windows \
     --domains "$DOMAIN" \
     --no-parent \
	"$1"
